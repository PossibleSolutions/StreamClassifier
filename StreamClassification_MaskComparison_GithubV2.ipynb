{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this script, the previously ditch/stream classified vector line geometries are rasterized and compared (summed) to a raster mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import dask_geopandas as dask_gpd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ditch/Stream split\n",
    "The dataset was first split into ditch and stream like features with threshold value 0.5 predicted_class. In this combined raster, ditch like features are emphasized. If both rasters have data (not equal to 0), “ditch_50m@1” raster values are used. \n",
    "\n",
    "Other option is to use a custom filter for the split. In this split, additional parameters were used in addition to the predicted_class as it seemed to overestimate the number of natural streams. Use the predicted_class if identification of streams is of high importance as this custom filter might see some natural streams as ditches. Lapland is an exception as there is a minimum amount of ditched areas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18775792\n",
      "16518532\n",
      "2257260\n"
     ]
    }
   ],
   "source": [
    "#using predicted_class\n",
    "\n",
    "filename = r\"Path\\ClassifiedStreams.parquet\"\n",
    "ddf = dask_gpd.read_parquet(filename, npartitions=2)\n",
    "df = ddf.compute()\n",
    "print(len(df))\n",
    "\n",
    "ditch = df.predicted_class_mean <= 0.5\n",
    "stream = df.predicted_class_mean > 0.5\n",
    "\n",
    "df[ditch].to_parquet(r\"Path\\ditch.parquet\")\n",
    "print(len(df[ditch]))\n",
    "df[stream].to_parquet(r\"Path\\stream.parquet\")\n",
    "print(len(df[stream]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18775792\n",
      "344469\n",
      "18431323\n"
     ]
    }
   ],
   "source": [
    "#using custom filter\n",
    "\n",
    "filename = r\"Path\\ClassifiedStreams.parquet\"\n",
    "ddf = dask_gpd.read_parquet(filename, npartitions=2)\n",
    "df = ddf.compute()\n",
    "print(len(df))\n",
    "\n",
    "stream = df[\n",
    "    (df['num_vertices'] > 6) &\n",
    "    (df['sinuosity'] > 1.02) &\n",
    "    (df['mean_distance_seq'] < 10) &\n",
    "    ((df['StreamProbRF'] > 0.6) | (df['StreamProbNN'] > 0.6))\n",
    "]\n",
    "\n",
    "stream.to_parquet(r\"Path\\stream.parquet\")\n",
    "print(len(stream))\n",
    "      \n",
    "ditch = df[\n",
    "    ~(\n",
    "        (df['num_vertices'] > 6) &\n",
    "        (df['sinuosity'] > 1.02) &\n",
    "        (df['mean_distance_seq'] < 10) &\n",
    "        ((df['StreamProbRF'] > 0.6) | (df['StreamProbNN'] > 0.6))\n",
    "    )\n",
    "]\n",
    "\n",
    "ditch.to_parquet(r\"Path\\ditch.parquet\")\n",
    "print(len(ditch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if you have a big dataset not fitting into memory, run in parts\n",
    "#run for both ditch and stream and comment the other option out\n",
    "filename = r\"Path\\ditch.parquet\"\n",
    "filename = r\"Path\\stream.parquet\"\n",
    "ddf = dask_gpd.read_parquet(filename, npartitions=8)\n",
    "ddf = ddf.repartition(npartitions=8)\n",
    "\n",
    "npartition=8\n",
    "for n in range(npartition):\n",
    "    # Get the 0th partition\n",
    "    partition = ddf.get_partition(n)\n",
    "    # Perform the buffer operation\n",
    "    buffer_distance = 50  # Buffer distance\n",
    "    partition['geometry'] = partition['geometry'].buffer(buffer_distance)\n",
    "    # Write the result to disk to free up memory\n",
    "    df = partition.compute()\n",
    "    out = rf\"Path\\ditch_buff50m.parquet{n}.parquet\"\n",
    "    out = rf\"Path\\stream_buff50m.parquet{n}.parquet\"\n",
    "    print(n, len(df))\n",
    "    df.to_parquet(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#spectate layers in qgis and merge them there\n",
    "do for both ditch and stream\n",
    "processing.run(\"native:mergevectorlayers\", {'LAYERS':['Path/stream_buff50m.parquet0.parquet|layername=stream_buff50m.parquet0','Path/stream_buff50m.parquet1.parquet|layername=stream_buff50m.parquet1','Path/stream_buff50m.parquet2.parquet|layername=stream_buff50m.parquet2','Path/stream_buff50m.parquet3.parquet|layername=stream_buff50m.parquet3','Path/stream_buff50m.parquet4.parquet|layername=stream_buff50m.parquet4','Path/stream_buff50m.parquet5.parquet|layername=stream_buff50m.parquet5','Path/stream_buff50m.parquet6.parquet|layername=stream_buff50m.parquet6','Path/stream_buff50m.parquet7.parquet|layername=stream_buff50m.parquet7'],'CRS':QgsCoordinateReferenceSystem('EPSG:3067'),'OUTPUT':'Path/stream_buff50m_all.parquet'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rasterize\n",
    "-with mask properties (resolution, extent, crs...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run for both ditch and stream\n",
    "\n",
    "processing.run(\"gdal:rasterize\", {'INPUT':'YourFile','FIELD':'predicted_class_mean','BURN':0,'USE_Z':False,'UNITS':0,'WIDTH':69600,'HEIGHT':118800,'EXTENT':'44000.000000000,740000.000000000,6594000.000000000,7782000.000000000 [EPSG:3067]','NODATA':0,'OPTIONS':'','DATA_TYPE':5,'INIT':None,'INVERT':False,'EXTRA':'','OUTPUT':'Path/50mbuff.tif'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assing minimum value or round up (optional)\n",
    "\n",
    "With float32 in some cases it seemed that e.g. a raster sum 1+3.29e-9 or similar might end up in a sum of 1.00 as the latter is summed to 0.00 due to lacking precision. dtype='float64' might work in some cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rioxarray\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import dask.array as da\n",
    "\n",
    "file = r\"Path\\ditch_50mbuff_compressed.tif\"\n",
    "out = r\"Path\\ditch_50mbuff_MinAdjusted.tif\"\n",
    "\n",
    "# Open the raster file and convert it into a DataArray\n",
    "ditch = rioxarray.open_rasterio(file, chunks={'band': 1, 'x': 1024, 'y': 1024})\n",
    "\n",
    "# Define the minimum value\n",
    "min_value = 0.001\n",
    "\n",
    "# Apply the minimum value\n",
    "adjusted_ditch = ditch.where(ditch < min_value, min_value)\n",
    "\n",
    "# Save the adjusted raster as a new file\n",
    "adjusted_ditch.rio.to_raster(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine rasters to emphasize ditch effect\n",
    "\n",
    "If both rasters have data (not equal to 0), “ditch_50m@1” raster values are used.\n",
    "If only the “stream_50m@1” raster has data, “stream_50m@1” raster values are used.\n",
    "If only the “ditch_50m@1” raster has data, “ditch_50m@1” raster values are used.\n",
    "\n",
    "The idea is that if there are ditches close to natural streams, their impact \"overwrites\"\n",
    "the natural impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rioxarray\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import dask.array as da\n",
    "\n",
    "out = r'Path\\CombinedStreamRaster.tif'\n",
    "\n",
    "# Read the data in chunks\n",
    "ditch = rioxarray.open_rasterio(r'Path\\ditch_50mbuff.tif', chunks={'band': 1, 'x': 1024, 'y': 1024})\n",
    "stream = rioxarray.open_rasterio(r'Path\\stream_50mbuff.tif', chunks={'band': 1, 'x': 1024, 'y': 1024})\n",
    "\n",
    "ditch_data = ditch[0]\n",
    "print('ditch read')\n",
    "stream_data = stream[0]\n",
    "print('stream read')\n",
    "\n",
    "# Create a new array to hold the result\n",
    "result = da.zeros_like(ditch_data)\n",
    "print('new array done')\n",
    "\n",
    "# Apply the conditions\n",
    "result = da.where((ditch_data != 0) & (stream_data != 0), ditch_data, result)\n",
    "result = da.where((ditch_data == 0) & (stream_data != 0), stream_data, result)\n",
    "result = da.where((ditch_data != 0) & (stream_data == 0), ditch_data, result)\n",
    "print('conditions set')\n",
    "\n",
    "# Save the result to a new raster file\n",
    "result_xarray = xr.DataArray(result, dims=(\"y\", \"x\"), coords={\"y\": ditch.y, \"x\": ditch.x})\n",
    "result_xarray.rio.write_crs(ditch.rio.crs, inplace=True)\n",
    "result_xarray.rio.to_raster(out, dtype='float32')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add 50m buffered peat production areas, fields and roads as ditches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ditch read\n",
      "stream read\n",
      "new array done\n",
      "conditions set\n"
     ]
    }
   ],
   "source": [
    "import rioxarray\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import dask.array as da\n",
    "\n",
    "FieldRoadPeatprod = r\"Path\\Masks\\TiePeltoTurvetuotantoBuffer50m.tif\"\n",
    "streams = r\"Path\\all_buff50m.tif\"\n",
    "out = r'Path\\CombinedStreamRaster.tif'\n",
    "\n",
    "# Read the data in chunks\n",
    "streams = rioxarray.open_rasterio(streams, chunks={'band': 1, 'x': 2048, 'y': 2048})\n",
    "FieldRoadPeatprod = rioxarray.open_rasterio(FieldRoadPeatprod, chunks={'band': 1, 'x': 2048, 'y': 2048})\n",
    "\n",
    "streams_data = streams[0]\n",
    "print('streams read')\n",
    "FieldRoadPeatprod_data = FieldRoadPeatprod[0]\n",
    "print('FieldRoadPeatprod read')\n",
    "\n",
    "# Apply the conditions\n",
    "streams_data = da.where(FieldRoadPeatprod_data != 0, 1, streams_data) #if fieldroadpeatland, then fieldroadpeatland else stream\n",
    "print('conditions set')\n",
    "\n",
    "# Save the result to a new raster file\n",
    "result_xarray = xr.DataArray(streams_data, dims=(\"y\", \"x\"), coords={\"y\": streams.y, \"x\": streams.x})\n",
    "result_xarray.rio.write_crs(streams.rio.crs, inplace=True)\n",
    "result_xarray.rio.to_raster(out, dtype='int8', compress='LZW', sparse_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare with mask\n",
    "\n",
    "-if categorical case, uint8 addition (e.g. 1+4) is enough without astype(np.float32)\n",
    "\n",
    "-if probabilistic case and the mask has uint8 values, they need to be converted to float first. \n",
    "Here mask has values 1 and 2, and the stream raster has float32 probablility values 0 - 1.\n",
    "by summing the values, the values in mask raster that do not overlap, remain unchanged (can be filtered with values 1.00 and 2.00) and\n",
    "-range 1.01 - 1.99 are the mask class 1 pixels that are on the vector line (ditch/stream) impact area (50 m buffer)\n",
    "-range 2.01 - 2.99 are the mask class 2 pixels that are on the vector line (ditch/stream) impact area (50 m buffer)\n",
    "\n",
    "both rasters are of same properties (resolution, extent, crs), if in your case not, resample first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rioxarray\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import dask.array as da\n",
    "\n",
    "Mask = r\"Path\\Mask.tif\"\n",
    "Streams = r\"Path\\CombinedStreamraster.tif\"\n",
    "out = r\"Path\\MaskWithStreamvalues.tif\"\n",
    "\n",
    "# Open the raster files with chunking\n",
    "mask = rioxarray.open_rasterio(Mask, chunks={'band': 1, 'x': 1024, 'y': 1024})\n",
    "stream = rioxarray.open_rasterio(Streams, chunks={'band': 1, 'x': 1024, 'y': 1024})\n",
    "\n",
    "# Add the values of stream to ditch\n",
    "result = (mask[0] * 10) + stream[0]\n",
    "# reclassify, mineral soil and peatland with natural streams to mineral soil and peatland\n",
    "result = da.where(result == 22, 20, result)\n",
    "result = da.where(result == 12, 10, result)\n",
    "\n",
    "# Save the result to a new raster file\n",
    "result_xarray = xr.DataArray(result, dims=(\"y\", \"x\"), coords={\"y\": mask.y, \"x\": mask.x})\n",
    "result_xarray.rio.write_crs(mask.rio.crs, inplace=True)\n",
    "result_xarray.rio.to_raster(out, dtype='uint8', compress='LZW', sparse_ok=True) #np.float32 if probability\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add additional classes that overwrite the base layer\n",
    "22 = Peat field (that overwrites the previous classes), 23 = Peat production areas (that overwrites the previous classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Peat fields\n",
    "\n",
    "import rioxarray\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import dask.array as da\n",
    "\n",
    "MaskWithStreams = r\"path\\MaskWithStreamvalues.tif\"\n",
    "turvepelto = r\"path\\turvepelto.tif\"\n",
    "out = r\"path\\MaskWithStreamvalues_TurvPelt.tif\"\n",
    "\n",
    "# Read the data in chunks\n",
    "MaskWithStreams = rioxarray.open_rasterio(MaskWithStreams, chunks={'band': 1, 'x': 2048, 'y': 2048})\n",
    "turvepelto = rioxarray.open_rasterio(turvepelto, chunks={'band': 1, 'x': 2048, 'y': 2048})\n",
    "turvepelto = turvepelto.rio.reproject_match(MaskWithStreams) #second raster in a different shape so its converted to match\n",
    "\n",
    "MaskWithStreams_data = MaskWithStreams[0]\n",
    "print('MaskWithStreams read')\n",
    "turvepelto_data = turvepelto[0]\n",
    "print('turvepelto read')\n",
    "\n",
    "# Apply the conditions\n",
    "MaskWithStreams_data = da.where(turvepelto_data != 0, 22, MaskWithStreams_data) #if turvepelto, then turvepelto else mask\n",
    "print('conditions set')\n",
    "\n",
    "# Save the result to a new raster file\n",
    "result_xarray = xr.DataArray(MaskWithStreams_data, dims=(\"y\", \"x\"), coords={\"y\": MaskWithStreams.y, \"x\": MaskWithStreams.x})\n",
    "result_xarray.rio.write_crs(MaskWithStreams.rio.crs, inplace=True)\n",
    "result_xarray.rio.to_raster(out, dtype='int8', compress='LZW', sparse_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Peat production areas\n",
    "\n",
    "import rioxarray\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import dask.array as da\n",
    "\n",
    "MaskWithStreams = r\"path\\MaskWithStreamvalues_TurvPelt.tif\"\n",
    "turvetuotantoalue = r\"path\\Turvetuotanto.tif\"\n",
    "out = r\"path\\MaskWithStreamvalues_TurvPelt_Turvetuot.tif\"\n",
    "\n",
    "# Read the data in chunks\n",
    "MaskWithStreams = rioxarray.open_rasterio(MaskWithStreams, chunks={'band': 1, 'x': 2048, 'y': 2048})\n",
    "turvetuotantoalue = rioxarray.open_rasterio(turvetuotantoalue, chunks={'band': 1, 'x': 2048, 'y': 2048})\n",
    "\n",
    "MaskWithStreams_data = MaskWithStreams[0]\n",
    "print('MaskWithStreams read')\n",
    "turvetuotantoalue_data = turvetuotantoalue[0]\n",
    "print('turvetuotantoalue read')\n",
    "\n",
    "# Apply the conditions\n",
    "MaskWithStreams_data = da.where(turvetuotantoalue_data != 0, 23, MaskWithStreams_data) #if turvetuotantoalue, then turvetuotantoalue else mask\n",
    "print('conditions set')\n",
    "\n",
    "# Save the result to a new raster file\n",
    "result_xarray = xr.DataArray(MaskWithStreams_data, dims=(\"y\", \"x\"), coords={\"y\": MaskWithStreams.y, \"x\": MaskWithStreams.x})\n",
    "result_xarray.rio.write_crs(MaskWithStreams.rio.crs, inplace=True)\n",
    "result_xarray.rio.to_raster(out, dtype='int8', compress='LZW', sparse_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compress end product for storage\n",
    "-if not done previously\n",
    "-by default this script compresses the output\n",
    "result_xarray.rio.to_raster(out, dtype='int8', compress='LZW', sparse_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Done in qgis\n",
    "\n",
    "Algorithm 'Translate (convert format)' starting…\n",
    "Input parameters:\n",
    "{ 'COPY_SUBDATASETS' : False, 'DATA_TYPE' : 0, 'EXTRA' : '', 'INPUT' : 'Path.tif', 'NODATA' : None, 'OPTIONS' : 'COMPRESS=LZW|TILED=YES|SPARSE_OK=YES', 'OUTPUT' : 'Path/_compressed.tif', 'TARGET_CRS' : None }\n",
    "\n",
    "GDAL command:\n",
    "gdal_translate -of GTiff -co COMPRESS=LZW -co TILED=YES -co SPARSE_OK=YES path path\n",
    "GDAL command output:\n",
    "Input file size is 69600, 118800 "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
